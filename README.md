
# Отчёт по Курсовой работе (Thread Pool).

## 1. Описание работы и структура

**Цель работы:**  
Разработать собственный пул потоков (`CustomThreadPoolExecutor`) с возможностью тонкой настройки параметров (количество потоков, размер очереди, резерв, время жизни), логированием ключевых событий и гибкой политикой отказа, а затем сравнить его производительность с пулом из стандартной библиотеки.

**Структура проекта:**
```
org.threadPool/
├── CustomExecutor.java                   — интерфейс пула потоков
├── CustomRejectedExecutionHandler.java   — политика отказа CallerRuns
├── CustomThreadFactory.java              — фабрика потоков
├── CustomThreadPoolExecutor.java         — реализация пула
├── Worker.java                           — логика выполнения задач воркером
├── CustomPoolTest.java                   — тесты нагрузки на CustomThreadPoolExecutor
└── FixedPoolTest.java                    — тесты нагрузки на FixedThreadPool(10)
```

## 2. Что реализовано

- **Интерфейс `CustomExecutor`**  
  Поддерживает методы `execute(Runnable)`, `submit(Callable<T>)`, а также `shutdown()` и `shutdownNow()`.

- **Пользовательская политика отказа**  
  `CustomRejectedExecutionHandler` реализует `CallerRunsPolicy`, выполняя задачи в вызывающем потоке при переполнении.

- **Кастомная фабрика потоков**  
  `CustomThreadFactory` присваивает потокам имена `<PoolName>-worker-<N>` и логирует создание.

- **Основной пул `CustomThreadPoolExecutor`**  
  - Параметры:  
    - `corePoolSize` – минимальное число потоков  
    - `maxPoolSize` – максимальное число потоков  
    - `keepAliveTime` – время жизни лишних потоков  
    - `queueSize` – размер каждой из N очередей  
    - `minSpareThreads` – резерв свободных потоков  
  - **Round-Robin** распределение по N очередям  
  - Динамическое масштабирование и поддержание резерва  
  - Логирование и graceful/force shutdown

## 3. Сравнение кастомного ThreadPool с FixedThreadPool

**Условия:**  
- Количество задач: 10 000 (на 1000 задач заметной разницы не обнаружено)
- Эмуляция выполнения задач с помощью sleep(10–100 ms)  
- Таймаут: 60 с

**Результаты:**  
| Пул                                    | Время (ms) | Tasks/sec | Латентность (ms) min・avg・max |
|----------------------------------------|------------|-----------|--------------------------------|
| **CustomThreadPoolExecutor (2-10-12-1)** | 51 334     | 194,80    | 10・55,18・101                 |
| **FixedThreadPool(10)**                | 55 359     | 180,64    | 10・54,87・101                 |

- CustomPool показал на **8 % выше throughput**, благодаря независимым очередям и снижению конкуренции.
- Средняя латентность обоих пулов сопоставима.

### Выводы
Тесты показывают, что при небольшом числе задач (200–1 000) стандартный FixedThreadPool(10) и кастомный пул схожи по пропускной способности, а при больших объёмах (10 000 задач) CustomThreadPoolExecutor начинает превосходить за счёт уменьшения конкуренции на очередях и гибкого масштабирования.
Таким образом, при высокой нагрузке архитектура с несколькими очередями и Round-Robin распределением показывает лучшие результаты.

## 4. Анализ влияния параметров на производительность

Было протестировано восемь конфигураций `CustomThreadPoolExecutor` на **1 000 задач** и получены следующие результаты:

| # | core | max  | queue | minSpare | Time (ms) | Throughput (tasks/sec) | Avg Latency (ms) |
|:-:|:----:|:----:|:-----:|:--------:|:---------:|:----------------------:|:----------------:|
| 1 |   2  |  10  |  12   |    1     |   5 768   |        173,37          |      55,02       |
| 2 |   1  |  10  |  12   |    1     |   5 827   |        171,61          |      55,62       |
| 3 |   2  |  20  |  12   |    1     |   4 626   |        216,17          |      56,19       |
| 4 |   2  |  10  |  20   |    1     |   5 893   |        169,69          |      55,09       |
| 5 |   2  |  10  |  10   |    4     |   9 290   |        107,64          |      54,18       |
| 6 |   4  |  10  |  30   |    1     |   6 798   |        147,10          |      56,54       |
| 7 |   1  |  10  |  30   |    1     |   6 032   |        165,78          |      55,08       |
| 8 |   2  |  50  |  10   |    1     |   2 895   |        345,42          |      54,28       |

---

### Выводы

1. **Превалирует большой `maxPoolSize`**  
   Конфигурация **#8 (2–50–10–1)** с `maxPoolSize=50` выдала **345 tasks/sec**, почти в два раза выше базовой. Это говорит о том, что при очень коротких `sleep(10–100 ms)` задачах дополнительные потоки эффективно загружаются и не создают слишком много контекстного переключения.

2. **Умеренный рост `maxPoolSize` помогает, но до порога**  
   Переход от `max=10` (#1) к `max=20` (#3) сразу поднимает throughput с 173 → 216 tasks/sec. Дальнейший рост до 50 (#8) дал ещё больший прирост. Однако в сценариях с более тяжёлыми или требовательными к CPU задачами слишком много потоков начнёт **конкурировать** за системные ресурсы, и выигрыша не будет.

3. **Размер очереди `queueSize`**  
   - Слишком большая очередь (`queue=20` или `30`) **затормаживает** рост пула, задачи ложатся в очередь вместо запуска новых потоков → throughput снижается (конфиги #4 и #6).  
   - Слишком маленькая очередь вместе с большим `maxPoolSize` стимулирует рост пула, но если `max` невелик — очередь переполняется и задачи идут через `CallerRuns` → throughput падает (конфиг #5, `minSpare=4`).

4. **`corePoolSize` и `minSpareThreads`**  
   - Уменьшение `core` до 1 (#2) дало незначимо худший результат по сравнению с core=2 (#1).  
   - Увеличение `core` до 4 (#6) без изменения `max` тоже не улучшило throughput: пул достигает 10 потоков, но переключения и увеличение очереди забирают выигрыш.  
   - Большой резерв (`minSpare=4`, #5) дал **самый худший** результат: лишние свободные потоки простаивают и не приносят пользы.


## 5. Принцип действия механизма распределения задач между очередями

1. Пул содержит **N = `maxPoolSize`** независимых `BlockingQueue<Runnable>`, по одной на каждый потенциальный поток.
2. Для каждой новой задачи вычисляется индекс очереди, куда будет помещена задача:
   ```java
   int idx = nextQueue.getAndIncrement() % N;
   ```
3. Далее задачи будут равномерно разносится по всем очередям по кругу: 0, 1, 2, … ,N−1, затем снова 0, 1 и т.д.
Каждый воркер читает задачи только из своей собственной очереди, поэтому нет единого блокирующего мьютекса на все задачи.

## 6. **Итоги**
1. **`corePoolSize` ≈ числу ядер**  
   Оптимально запускать потоков столько же, сколько аппаратных или виртуальных ядер.

2. **`maxPoolSize` ≈ 2–3 × core**  
   Позволяет обрабатывать пики нагрузки (IO-bound задачи и т.п.).

3. **`queueSize` ≈ 4–8 × core**  
   Средняя очередь сглаживает кратковременные всплески задач без немедленной эскалации потоков.

4. **`minSpareThreads` = 1**  
   Один резервный поток обеспечивает мгновенный отклик без постоянных затрат на поддержание «горячих» потоков.

5. **Round-Robin снижает contention**  
   При высоких объёмах задач разделение на N очередей вместо одной общей уменьшает нагрузку на синхронизацию и улучшает throughput.
